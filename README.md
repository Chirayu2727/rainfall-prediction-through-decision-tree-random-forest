DECISION TREE in Machine Learning
A decision tree in machine learning is a versatile, interpretable algorithm used for predictive modelling.
It structures decisions based on input data, making it suitable for both classification and regression tasks. 
This article delves into the components, terminologies, construction, and advantages of decision trees, exploring their applications and learning algorithms.
A decision tree is a type of supervised learning algorithm that is commonly used in machine learning to model and predict outcomes based on input data. 
It is a tree-like structure where each internal node tests on attribute, each branch corresponds to attribute value and each leaf node represents the final decision or prediction. 
The decision tree algorithm falls under the category of supervised learning. They can be used to solve both regression and classification problems.

RANDOM FOREST in machine learning
Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time.
For classification tasks, the output of the random forest is the class selected by most trees.
For regression tasks, the mean or average prediction of the individual trees is returned.
Random decision forests correct for decision trees' habit of overfitting to their training set

ENSEMBLING in random forest
Ensemble learning is a combination of several machine learning models in one problem. These models are known as weak learners.
The intuition is that when you combine several weak learners, they can become strong learners.
Each weak learner is fitted on the training set and provides predictions obtained. The final prediction result is computed by combining the results from all the weak learners. 
